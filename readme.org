#+title:    Challenge
#+author:   Alberto Valdez
#+email:    avq5ac1@gmail.com
#+SETUPFILE: https://albertov5.github.io/org-html-themes/org/theme-readtheorg.setup
#+OPTIONS: num:nil
#+PROPERTY: header-args :mkdirp yes :dir . :exports both
#+PROPERTY: header-args:shell :results drawer :wrap example :results silent
#+PROPERTY: header-args:python :exports both :results output replace
#+PROPERTY: header-args:sql :engine postgresql :dbhost localhost :dbuser albertovaldez :database movie_data :results value html :post attr_wrap(data=*this*)

#+NAME: attr_wrap
#+BEGIN_SRC python :var data="" :results silent :exports none
import xml.etree.ElementTree as ET

def build_row(parent, data, tag):
    child = ET.SubElement(parent, "tr")
    for s in data.split("\t"):
        ET.SubElement(child, tag).text = s
    return child
# XML
data = data.split("\n")
table = ET.Element("table")
build_row(table, data[0], "th")
for row in data[1:-1]:
    build_row(table, row, "td")
ET.dump(table)
#+END_SRC

* Extract, Transform and Load Movie Data.

** Overview

In this analysis, we mainly focused on the heuristics of the ETL process. We were able to clean data thoroughly and get a better view of our data using Python and SQL to load the results into a database.

As this is our first time dealing with this amount of data in this fashion, we used a very procedural approach to make sure all our steps were correct. At the same time, we created a few functions to reuse in future endeavors.

** Results

We managed to store the data in our SQL database by connecting to it through Python.

#+begin_src python
from sqlalchemy import create_engine

db_dns = "postgresql://albertovaldez@localhost:5432/movie_data2"
engine = create_engine(db_dns)
query = "SELECT COUNT(*) FROM movies;"
count= engine.execute(query).fetchall()
print(count)
#+end_src

#+RESULTS:
: [(6051,)]

*** Query of the Movies table
#+attr_html: :width 800px
[[./movies_query.png]]
We can also use the basic SQL queries from terminal or any SQL supporting environment.

#+begin_src sql
SELECT COUNT(*) FROM movies;
#+end_src

#+RESULTS:
#+begin_export html
<table><tr><th>count</th></tr><tr><td>6051</td></tr></table>
#+end_export

#+begin_src sql
SELECT index, imdb_id FROM movies ORDER BY index DESC LIMIT 5;
#+end_src

#+RESULTS:
#+begin_export html
<table><tr><th>index</th><th>imdb_id</th></tr><tr><td>6051</td><td>tt3859310</td></tr><tr><td>6050</td><td>tt5795086</td></tr><tr><td>6049</td><td>tt6304162</td></tr><tr><td>6048</td><td>tt5390066</td></tr><tr><td>6047</td><td>tt5639354</td></tr></table>
#+end_export

*** Query of the Ratings table

#+attr_html: :width 700px
[[./ratings_query.png]]

** Summary

The most important part was joining our two tables where we made a few key judgements on the tables we wanted to keep and which one were not worth to join.

| Wiki                  | Movielens            | Resolution                             |
|-----------------------+----------------------+----------------------------------------|
| title_wiki            | title_kaggle         | DROP WIKIPEDIA                         |
| running_time          | runtime              | KEEP KAGGLE, FILL ZEROS WITH WIKIPEDIA |
| budget_wiki           | budget_kaggle        | KEEP KAGGLE, FILL ZEROS WITH WIKIPEDIA |
| box_office            | revenue              | KEEP KAGGLE, FILL ZEROS WITH WIKIPEDIA |
| release_date_wiki     | release_date_kaggle  | DROP WIKIPEDIA                         |
| language              | original_language    | DROP WIKIPEDIA                         |
| Production company(s) | production_companies | DROP WIKIPEDIA                         |

** Closing Thoughts

ETL may not be the most comfortable part of the data pipeline but its probably the most crucial. Clean data has become more and more important in the way we solve problems, design programs, and learn about the world.
